{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于集成学习的 Amazon 用户评论质量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、案例简介\n",
    "\n",
    "随着电商平台的兴起，以及疫情的持续影响，线上购物在我们的日常生活中扮演着越来越重要的角色。在进行线上商品挑选时，评论往往是我们十分关注的一个方面。然而目前电商网站的评论质量参差不齐，甚至有水军刷好评或者恶意差评的情况出现，严重影响了顾客的购物体验。因此，对于评论质量的预测成为电商平台越来越关注的话题，如果能自动对评论质量进行评估，就能根据预测结果避免展现低质量的评论。本案例中我们将基于集成学习的方法对 Amazon 现实场景中的评论质量进行预测。\n",
    "\n",
    "## 二、实验说明\n",
    "\n",
    "本案例中完成两种集成学习算法的实现（Bagging、AdaBoost.M1），其中基分类器要求使用 SVM 和决策树两种，因此，一共需要对比四组结果（[AUC](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) 作为评价指标）：\n",
    "\n",
    "* Bagging + SVM\n",
    "* Bagging + 决策树\n",
    "* AdaBoost.M1 + SVM\n",
    "* AdaBoost.M1 + 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数据概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "train_df = pd.read_csv('./data/train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7885</td>\n",
       "      <td>3901</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52087</td>\n",
       "      <td>47978</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5701</td>\n",
       "      <td>3667</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47191</td>\n",
       "      <td>40892</td>\n",
       "      <td>Keep your expectations low.  Really really low...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40957</td>\n",
       "      <td>15367</td>\n",
       "      <td>\"they dont make em like this no more...\"well.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57034</th>\n",
       "      <td>58315</td>\n",
       "      <td>29374</td>\n",
       "      <td>If you like beautifully shot, well acted films...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57035</th>\n",
       "      <td>23328</td>\n",
       "      <td>45548</td>\n",
       "      <td>This is a great set of films Wayne did Fox and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57036</th>\n",
       "      <td>27203</td>\n",
       "      <td>42453</td>\n",
       "      <td>It's what's known as a comedy of manners. It's...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57037</th>\n",
       "      <td>33992</td>\n",
       "      <td>44891</td>\n",
       "      <td>Ellen can do no wrong as far a creating wonder...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57038</th>\n",
       "      <td>27478</td>\n",
       "      <td>19198</td>\n",
       "      <td>I agree with everyone else that this is a grea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57039 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID   asin                                         reviewText  \\\n",
       "0            7885   3901  First off, allow me to correct a common mistak...   \n",
       "1           52087  47978  I am really troubled by this Story and Enterta...   \n",
       "2            5701   3667  A near-perfect film version of a downright glo...   \n",
       "3           47191  40892  Keep your expectations low.  Really really low...   \n",
       "4           40957  15367  \"they dont make em like this no more...\"well.....   \n",
       "...           ...    ...                                                ...   \n",
       "57034       58315  29374  If you like beautifully shot, well acted films...   \n",
       "57035       23328  45548  This is a great set of films Wayne did Fox and...   \n",
       "57036       27203  42453  It's what's known as a comedy of manners. It's...   \n",
       "57037       33992  44891  Ellen can do no wrong as far a creating wonder...   \n",
       "57038       27478  19198  I agree with everyone else that this is a grea...   \n",
       "\n",
       "       overall  votes_up  votes_all  label  \n",
       "0          5.0         6          7      0  \n",
       "1          3.0        99        134      0  \n",
       "2          4.0        14         14      1  \n",
       "3          1.0         4          7      0  \n",
       "4          5.0         3          6      0  \n",
       "...        ...       ...        ...    ...  \n",
       "57034      2.0        12         21      0  \n",
       "57035      5.0        15         18      0  \n",
       "57036      3.0         4          5      0  \n",
       "57037      5.0         4          5      0  \n",
       "57038      2.0         5          5      1  \n",
       "\n",
       "[57039 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57039 entries, 0 to 57038\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   reviewerID  57039 non-null  int64  \n",
      " 1   asin        57039 non-null  int64  \n",
      " 2   reviewText  57039 non-null  object \n",
      " 3   overall     57039 non-null  float64\n",
      " 4   votes_up    57039 non-null  int64  \n",
      " 5   votes_all   57039 non-null  int64  \n",
      " 6   label       57039 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 3.0+ MB\n",
      "None\n",
      "          reviewerID          asin       overall      votes_up     votes_all  \\\n",
      "count   57039.000000  57039.000000  57039.000000  57039.000000  57039.000000   \n",
      "mean    33359.761865  19973.170866      3.535178     12.387594     18.475850   \n",
      "std     30016.804127  14104.410152      1.529742     45.130499     50.149683   \n",
      "min        50.000000      0.000000      1.000000      0.000000      5.000000   \n",
      "25%      9235.000000   8218.000000      2.000000      4.000000      6.000000   \n",
      "50%     22589.000000  17635.000000      4.000000      6.000000     10.000000   \n",
      "75%     53170.000000  30875.000000      5.000000     11.000000     18.000000   \n",
      "max    123767.000000  50051.000000      5.000000   6084.000000   6510.000000   \n",
      "\n",
      "              label  \n",
      "count  57039.000000  \n",
      "mean       0.226196  \n",
      "std        0.418371  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max        1.000000  \n",
      "0    44137\n",
      "1    12902\n",
      "Name: label, dtype: int64\n",
      "5.0    23365\n",
      "4.0    10104\n",
      "1.0     9970\n",
      "3.0     7232\n",
      "2.0     6368\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(train_df.describe())\n",
    "print(train_df.label.value_counts())\n",
    "print(train_df.overall.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次数据来源于 Amazon 电商平台，包含超过 50,000 条用户在购买商品后留下的评论，各列的含义如下：\n",
    "\n",
    "* reviewerID：用户 ID\n",
    "* asin：商品 ID\n",
    "* reviewText：英文评论文本\n",
    "* overall：用户对商品的打分（1-5）\n",
    "* votes_up：认为评论有用的点赞数（只在训练集出现）\n",
    "* votes_all：该评论得到的总评价数（只在训练集出现）\n",
    "* label：评论质量的 label，1 表示高质量，0 表示低质量（只在训练集出现）\n",
    "\n",
    "评论质量的 label 来自于其他用户对评论的 votes，votes_up/votes_all ≥ 0.9 的作为高质量评论。此外测试集包含一个额外的列Id，标识了每一个测试的样例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、比赛提交格式\n",
    "\n",
    "课程页面：https://aistudio.baidu.com/aistudio/education/dashboard\n",
    "\n",
    "提交文件需要对测试集中每一条评论给出预测为高质量的概率，每行包括一个Id（和测试集对应）以及预测的概率Predicted（0-1的浮点数），用逗号分隔。示例提交格式如下：\n",
    "\n",
    "```\n",
    "Id,Predicted\n",
    "0,0.9\n",
    "1,0.45\n",
    "2,0.78\n",
    "...\n",
    "```\n",
    "命名为`result.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意除了提交比赛，还需要像之前作业一样在学堂在线提交代码和报告（不包括数据）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID   asin  overall\n",
      "0            7885   3901      5.0\n",
      "1           52087  47978      3.0\n",
      "2            5701   3667      4.0\n",
      "3           47191  40892      1.0\n",
      "4           40957  15367      5.0\n",
      "...           ...    ...      ...\n",
      "57034       58315  29374      2.0\n",
      "57035       23328  45548      5.0\n",
      "57036       27203  42453      3.0\n",
      "57037       33992  44891      5.0\n",
      "57038       27478  19198      2.0\n",
      "\n",
      "[57039 rows x 3 columns]\n",
      "(57039, 3)\n",
      "(57039,)\n",
      "          Id  reviewerID   asin  \\\n",
      "0          0       82947  37386   \n",
      "1          1       10154  23543   \n",
      "2          2        5789   5724   \n",
      "3          3        9198   5909   \n",
      "4          4       33252  21214   \n",
      "...      ...         ...    ...   \n",
      "11203  11203       18250  35309   \n",
      "11204  11204        3200   2130   \n",
      "11205  11205       37366  41971   \n",
      "11206  11206        1781  33089   \n",
      "11207  11207       26372  35457   \n",
      "\n",
      "                                              reviewText  overall  \n",
      "0      I REALLY wanted this series but I am in SHOCK ...      1.0  \n",
      "1      I have to say that this is a work of art for m...      4.0  \n",
      "2      Alien 3 is certainly the most controversal fil...      3.0  \n",
      "3      I love this film...preachy?  Well, of course i...      5.0  \n",
      "4      Even though I previously bought the Gamera Dou...      5.0  \n",
      "...                                                  ...      ...  \n",
      "11203  I honestly never heard of the graphic novel un...      5.0  \n",
      "11204  Archie Bunker's command to stifle YOURSELF! wa...      5.0  \n",
      "11205  In LSD - My Problem Child, Albert Hoffman wrot...      5.0  \n",
      "11206  I have owned this DVD for over a year now and ...      5.0  \n",
      "11207  This movie is just a slap in the face [or othe...      1.0  \n",
      "\n",
      "[11208 rows x 5 columns]\n",
      "       reviewerID   asin  overall\n",
      "0           82947  37386      1.0\n",
      "1           10154  23543      4.0\n",
      "2            5789   5724      3.0\n",
      "3            9198   5909      5.0\n",
      "4           33252  21214      5.0\n",
      "...           ...    ...      ...\n",
      "11203       18250  35309      5.0\n",
      "11204        3200   2130      5.0\n",
      "11205       37366  41971      5.0\n",
      "11206        1781  33089      5.0\n",
      "11207       26372  35457      1.0\n",
      "\n",
      "[11208 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText'])\n",
    "print(train_x)\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "test_df = pd.read_csv('./data/test.csv', sep='\\t')\n",
    "print(test_df)\n",
    "test_x = test_df.drop(columns=['Id','reviewText'])\n",
    "print(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单决策树\n",
    "使用决策树观察发现不控制树深度和最小叶节点的情况下训练集的成功率为100%。  \n",
    "说明该树完全生长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039,)\n",
      "the accuracy of train result is 1.000000\n",
      "teh accuracy of train result by acc_score is 1.000000\n",
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 0)\n",
    "DT.fit(train_x, train_y)\n",
    "pred_train_y = DT.predict(train_x)\n",
    "#test_y = DT.predict(test_x)\n",
    "print(pred_train_y.shape)\n",
    "print(\"the accuracy of train result is %.6f\" %(DT.score(train_x, train_y)))\n",
    "print(\"teh accuracy of train result by acc_score is %.6f\" %(accuracy_score(train_y, pred_train_y)))\n",
    "#print(len(test_y))\n",
    "print(pred_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看数据倾斜程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    44137\n",
      "1    12902\n",
      "Name: label, dtype: int64\n",
      "0.7738038885674714\n"
     ]
    }
   ],
   "source": [
    "print(train_df.label.value_counts())\n",
    "print(len(train_df.label[train_df.label == 0])/len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现数据严重倾斜，全部预测0，准确率也有77%。  \n",
    "根据结果可以发现，由于数据严重不平衡，分类器简单粗暴的将结果投给标签多的一类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039,)\n",
      "the accuracy of train result is 0.773804\n",
      "the accuracy of train result by acc_score is 0.773804\n",
      "the accuracy of verify result is 0.776736\n",
      "the AUC of verify is 0.722470\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "trai_x, veri_x, trai_y, veri_y = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state = 4, min_samples_leaf = 10, max_depth = 3)\n",
    "DT.fit(trai_x, trai_y)\n",
    "pred_train_y = DT.predict(train_x)\n",
    "pred_veri_y = DT.predict(veri_x)\n",
    "prob_y = DT.predict_proba(veri_x)\n",
    "#test_y = DT.predict(test_x)\n",
    "print(pred_train_y.shape)\n",
    "print(\"the accuracy of train result is %.6f\" %(DT.score(train_x, train_y)))\n",
    "print(\"the accuracy of train result by acc_score is %.6f\" %(accuracy_score(train_y, pred_train_y)))\n",
    "print(\"the accuracy of verify result is %.6f\" %(accuracy_score(veri_y, pred_veri_y)))\n",
    "print(\"the AUC of verify is %.6f\" %(roc_auc_score(veri_y, prob_y[:,1])))\n",
    "print(pred_train_y)\n",
    "print(pred_train_y[1000:1030])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据平衡\n",
    "尝试对数据重采样来balance label。(之后发现工具可以有参数来自动balance数据。。。。）  \n",
    "可以发现平衡后的数据虽然准确率下降了，但是分类器参与其中了,因为训练集的结果不单单只有0了。  \n",
    "但是发现没有办法更好的提升准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12902\n",
      "1    12902\n",
      "Name: label, dtype: int64\n",
      "(25804,)\n",
      "(20643,)\n",
      "The accuracy of train result is 0.701691\n",
      "The accuracy of train result by acc_score is 0.701691\n",
      "The accuracy of verify result is 0.698508\n",
      "The AUC of verify is 0.723416\n",
      "[0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_df0 = train_df[train_df.label == 0].sample(n=12902)\n",
    "df = train_df0.append(train_df[train_df.label==1])\n",
    "df = df.sample(frac=1)\n",
    "print(df.label.value_counts())\n",
    "trai_x = df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "trai_y = df.label.values\n",
    "print(trai_y.shape)\n",
    "test_df = pd.read_csv('./data/test.csv', sep='\\t')\n",
    "\n",
    "trai_x, veri_x, trai_y, veri_y = train_test_split(trai_x, trai_y, test_size=0.2, random_state=0)\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state = 0, min_samples_leaf = 30, max_depth = 5)\n",
    "DT.fit(trai_x, trai_y)\n",
    "pred_train_y = DT.predict(trai_x)\n",
    "pred_veri_y = DT.predict(veri_x)\n",
    "prob_y = DT.predict_proba(veri_x)\n",
    "print(pred_train_y.shape)\n",
    "print(\"The accuracy of train result is %.6f\" %(DT.score(trai_x, trai_y)))\n",
    "print(\"The accuracy of train result by acc_score is %.6f\" %(accuracy_score(trai_y, pred_train_y)))\n",
    "print(\"The accuracy of verify result is %.6f\" %(accuracy_score(veri_y, pred_veri_y)))\n",
    "print(\"The AUC of verify is %.6f\" %(roc_auc_score(veri_y, prob_y[:,1])))\n",
    "#print(len(test_y))\n",
    "#print(test_y)\n",
    "print(pred_train_y[1000:1030])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和上一个cell一样，只不过手动balance数据的方式不一样。  \n",
    "np.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID   asin  overall  label\n",
      "0            7885   3901      5.0      0\n",
      "1           52087  47978      3.0      0\n",
      "2            5701   3667      4.0      1\n",
      "3           47191  40892      1.0      0\n",
      "4           40957  15367      5.0      0\n",
      "...           ...    ...      ...    ...\n",
      "57034       58315  29374      2.0      0\n",
      "57035       23328  45548      5.0      0\n",
      "57036       27203  42453      3.0      0\n",
      "57037       33992  44891      5.0      0\n",
      "57038       27478  19198      2.0      1\n",
      "\n",
      "[57039 rows x 4 columns]\n",
      "(25804, 3)\n",
      "(12902, 4) (12902, 4)\n",
      "(25804,)\n",
      "the accuracy of train result is 0.699194\n",
      "the accuracy of train result by acc_score is 0.699194\n"
     ]
    }
   ],
   "source": [
    "tra_x = train_df.drop(columns=['reviewText','votes_all','votes_up'])\n",
    "print(tra_x)\n",
    "#print(train_x)\n",
    "train1 = tra_x[tra_x.label==1].values\n",
    "train0 = tra_x[tra_x.label==0].values\n",
    "train0i = np.random.choice(len(train0), len(train1))\n",
    "train0 = train0[train0i]\n",
    "train = np.append(train0,train1,axis=0)\n",
    "np.random.shuffle(train)\n",
    "#tra_x = train[:,2].reshape(-1,1)\n",
    "tra_x = train[:,:-1]\n",
    "#tra_x = train\n",
    "tra_y = train[:,-1]\n",
    "print(tra_x.shape)\n",
    "print(train1.shape, train0.shape)\n",
    "DT = DecisionTreeClassifier(random_state = 0, min_samples_leaf = 30, max_depth = 5)\n",
    "DT.fit(tra_x, tra_y)\n",
    "pred_train_y = DT.predict(tra_x)\n",
    "#test_y = DT.predict(test_x[:,2])\n",
    "print(pred_train_y.shape)\n",
    "print(\"the accuracy of train result is %.6f\" %(DT.score(tra_x, tra_y)))\n",
    "print(\"the accuracy of train result by acc_score is %.6f\" %(accuracy_score(tra_y, pred_train_y)))\n",
    "#print(len(test_y))\n",
    "#print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 改造特征\n",
    "构造特征，将商品和用户的id换成商品id和用户id的频率  \n",
    "发现效果同样一般"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Keep your expectations low.  Really really low...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>\"they dont make em like this no more...\"well.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57034</th>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>If you like beautifully shot, well acted films...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57035</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a great set of films Wayne did Fox and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57036</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>It's what's known as a comedy of manners. It's...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57037</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Ellen can do no wrong as far a creating wonder...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57038</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>I agree with everyone else that this is a grea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57039 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID  asin                                         reviewText  \\\n",
       "0              33     5  First off, allow me to correct a common mistak...   \n",
       "1               6     4  I am really troubled by this Story and Enterta...   \n",
       "2              29     1  A near-perfect film version of a downright glo...   \n",
       "3               6     4  Keep your expectations low.  Really really low...   \n",
       "4               6     8  \"they dont make em like this no more...\"well.....   \n",
       "...           ...   ...                                                ...   \n",
       "57034          15    21  If you like beautifully shot, well acted films...   \n",
       "57035          27     1  This is a great set of films Wayne did Fox and...   \n",
       "57036          10     3  It's what's known as a comedy of manners. It's...   \n",
       "57037           8     1  Ellen can do no wrong as far a creating wonder...   \n",
       "57038           9     1  I agree with everyone else that this is a grea...   \n",
       "\n",
       "       overall  votes_up  votes_all  label  \n",
       "0          5.0         6          7      0  \n",
       "1          3.0        99        134      0  \n",
       "2          4.0        14         14      1  \n",
       "3          1.0         4          7      0  \n",
       "4          5.0         3          6      0  \n",
       "...        ...       ...        ...    ...  \n",
       "57034      2.0        12         21      0  \n",
       "57035      5.0        15         18      0  \n",
       "57036      3.0         4          5      0  \n",
       "57037      5.0         4          5      0  \n",
       "57038      2.0         5          5      1  \n",
       "\n",
       "[57039 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asin = dict(train_df['asin'].value_counts())\n",
    "asin_count = train_df['asin'].apply(lambda x: asin[x])\n",
    "reviewid = dict(train_df['reviewerID'].value_counts())\n",
    "reviewid_count = train_df['reviewerID'].apply(lambda x: reviewid[x])\n",
    "train_df['asin'] = asin_count\n",
    "train_df['reviewerID'] = reviewid_count\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID  asin  overall\n",
      "0              33     5      5.0\n",
      "1               6     4      3.0\n",
      "2              29     1      4.0\n",
      "3               6     4      1.0\n",
      "4               6     8      5.0\n",
      "...           ...   ...      ...\n",
      "57034          15    21      2.0\n",
      "57035          27     1      5.0\n",
      "57036          10     3      3.0\n",
      "57037           8     1      5.0\n",
      "57038           9     1      2.0\n",
      "\n",
      "[57039 rows x 3 columns]\n",
      "(57039, 3)\n",
      "(57039,)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText'])\n",
    "print(train_x)\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039,)\n",
      "The accuracy of train result is 0.693771\n",
      "The accuracy of train result by acc_score is 0.693771\n",
      "The accuracy of verify result is 0.700824\n",
      "The AUC of verify is 0.786613\n"
     ]
    }
   ],
   "source": [
    "trai_x, veri_x, trai_y, veri_y = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state = 4,class_weight = 'balanced', min_samples_leaf = 10, max_depth = 3)\n",
    "DT.fit(trai_x, trai_y)\n",
    "pred_train_y = DT.predict(train_x)\n",
    "pred_veri_y = DT.predict(veri_x)\n",
    "prob_y = DT.predict_proba(veri_x)\n",
    "#test_y = DT.predict(test_x)\n",
    "print(pred_train_y.shape)\n",
    "print(\"The accuracy of train result is %.6f\" %(DT.score(train_x, train_y)))\n",
    "print(\"The accuracy of train result by acc_score is %.6f\" %(accuracy_score(train_y, pred_train_y)))\n",
    "print(\"The accuracy of verify result is %.6f\" %(accuracy_score(veri_y, pred_veri_y)))\n",
    "print(\"The AUC of verify is %.6f\" %(roc_auc_score(veri_y, prob_y[:,1])))\n",
    "#print(pred_train_y)\n",
    "#print(pred_train_y[1000:1030])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 尝试对reviewText做分析  \n",
    "并且除了决策树，还使用了朴素贝叶斯和svm来观察  \n",
    "效果同样一般"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45631, 136519), (11408, 136519))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "train_x = train_df.reviewText.values\n",
    "train_y = train_df.label.values\n",
    "train_x, verify_x, train_y, verify_y = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "vectorizer = CountVectorizer()\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "verify_x = vectorizer.transform(verify_x)\n",
    "train_x.shape, verify_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45631,)\n",
      "The accuracy of train result is 0.693717\n",
      "The accuracy of train result by acc_score is 0.693717\n",
      "The accuracy of verify result is 0.684257\n",
      "The AUC of verify is 0.582870\n",
      "[0 1 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier(class_weight='balanced', min_samples_leaf = 10, max_depth = 1)\n",
    "DT.fit(train_x, train_y)\n",
    "pred_train_y = DT.predict(train_x)\n",
    "pred_verify_y = DT.predict(verify_x)\n",
    "prob_y = DT.predict_proba(verify_x)\n",
    "print(pred_train_y.shape)\n",
    "print(\"The accuracy of train result is %.6f\" %(DT.score(train_x, train_y)))\n",
    "print(\"The accuracy of train result by acc_score is %.6f\" %(accuracy_score(train_y, pred_train_y)))\n",
    "print(\"The accuracy of verify result is %.6f\" %(accuracy_score(verify_y, pred_verify_y)))\n",
    "print(\"The AUC of verify is %.6f\" %(roc_auc_score(verify_y, prob_y[:,1])))\n",
    "print(pred_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train by BernoulliNB is : 0.747540\n",
      "Accuracy verify by BernoulliNB is : 0.724492\n",
      "The AUC by BernoulliNB of verify is 0.706235\n"
     ]
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(train_x,train_y)\n",
    "pred_train_y = BNB.predict(train_x)\n",
    "pred_verify_y = BNB.predict(verify_x)\n",
    "prob_y = BNB.predict_proba(verify_x)\n",
    "verify_acc = accuracy_score(pred_verify_y, verify_y)\n",
    "train_acc = accuracy_score(pred_train_y, train_y)\n",
    "print(\"Accuracy train by BernoulliNB is : %.6f\" %(train_acc))\n",
    "print(\"Accuracy verify by BernoulliNB is : %.6f\" %(verify_acc))\n",
    "print(\"The AUC by BernoulliNB of verify is %.6f\" %(roc_auc_score(verify_y, prob_y[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC(probability=True)\n",
    "SVM.fit(train_x, train_y)\n",
    "pred_train_y = SVM.predict(train_x)\n",
    "pred_y = SVM.predict(verify_x)\n",
    "prob_y = SVM.predict_proba(verify_x)\n",
    "print(\"Accuracy train by svm is %.6f \" %(accuracy_score(pred_train_y, train_y)))\n",
    "print(\"Accuracy verify by svm is %.6f\" %(accuracy_score(pred_y, verify_y))) \n",
    "print(\"AUC of verify by svm is %.6f\" %(roc_auc_score(verify_y, prob_y[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only svm\n",
    "使用svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reviewerID', 'asin', 'overall'], dtype='object')\n",
      "(57039, 3)\n",
      "(57039,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of train result by svm is 0.780010\n"
     ]
    }
   ],
   "source": [
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText'])\n",
    "print(train_x.columns)\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "test_df = pd.read_csv('./data/test.csv', sep='\\t')\n",
    "\n",
    "\n",
    "SVM = SVC()\n",
    "SVM.fit(train_x, train_y)\n",
    "pred_train_y = SVM.predict(train_x)\n",
    "#\n",
    "#test_y = SVM.predict(test_x)\n",
    "print(\"the accuracy of train result by svm is %.6f\" %(accuracy_score(pred_train_y, train_y)))\n",
    "#print(len(test_y))\n",
    "#print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((45631, 3), (11408, 3), (45631,), (11408,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_y.shape)\n",
    "test_df = pd.read_csv('./data/test.csv', sep='\\t')\n",
    "#train_x\n",
    "test_x = test_df.drop(columns=['Id','reviewText'])\n",
    "\n",
    "train_x, verify_x, train_y, verify_y = train_test_split(train_x, train_y, test_size = 0.2, random_state = 0)\n",
    "train_x.shape, verify_x.shape, train_y.shape, verify_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagging 算法实现  \n",
    "* 数据平衡  \n",
    "在探索尝试时发现，如果训练数据标签不平衡会导致数据bagging实现了如果原数据label不平衡，在采样时平衡label比例。（下面也有实验对比）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging(object):   \n",
    "    def __init__(self, sample_num=None, sample_size=None, algo='DT', class_weight=None, max_depth=None, min_samples_leaf=None, C=1.0, gamma='auto', kernel='rbf', balance=1):\n",
    "        self.algo = algo\n",
    "        self.sample_num = sample_num\n",
    "        self.sample_size = sample_size\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.C = C  # svc parameter\n",
    "        self.gamma = gamma   # svc parameter\n",
    "        self.kernel = kernel   # svc parameter\n",
    "        self.p_num = 0  # population number\n",
    "        self.classes_num = {}  # for store sample num of each class, ex: Suppose in binary classification, label is 0 & 1, the sapmple_szie=100, this variable may like this: {0:30,1:70}\n",
    "        self.algo_model = [] # store the batch of algo model.\n",
    "        self.p0 = []   # population number of target 0\n",
    "        self.P1 = []\n",
    "        self.p = []\n",
    "        self.balance = balance\n",
    "        self.acc = []\n",
    "        self.class_weight = class_weight\n",
    "        \n",
    "    def b_sampling_class(self):  # sample with data balance, make sure use the minimum data volume\n",
    "        less = len(self.p0) if len(self.p0) < len(self.p1) else len(self.p1)\n",
    "        if (self.sample_size/2)/less > 1:  # the sample size allocate to each class big than the minimum class size\n",
    "            s0i = np.random.choice(len(self.p0), less)\n",
    "            s1i = np.random.choice(len(self.p1), less)\n",
    "        else:\n",
    "            s0i = np.random.choice(len(self.p0), int(self.sample_size/2))\n",
    "            s1i = np.random.choice(len(self.p1), int(self.sample_size/2))\n",
    "        s0 = self.p0[s0i]\n",
    "        s1 = self.p1[s1i]\n",
    "        s = np.append(s0, s1, axis=0)\n",
    "        np.random.shuffle(s)\n",
    "        #print(\"in balance sampling, s shape\", end=':')\n",
    "        #print(s.shape)\n",
    "        #print(collections.Counter(s[:,-1]))\n",
    "        return s\n",
    "\n",
    "    def sampling_class(self):\n",
    "        si = np.random.choice(self.p_num, self.sample_size)\n",
    "        s = self.p[si]\n",
    "        #print(\"in non-balance sampling, s shape\", end=' :')\n",
    "        #print(s.shape)\n",
    "        #print(collections.Counter(s[:,-1]))\n",
    "        return s\n",
    "    \n",
    "    def sampling(self):\n",
    "        if self.balance == 1:\n",
    "            return self.b_sampling_class()\n",
    "        else:\n",
    "            return self.sampling_class()\n",
    "                \n",
    "    def model_gen(self, clf, S):\n",
    "        self.algo_model.append(clf.fit(S[:,:-1], S[:,-1]))\n",
    "        prd = clf.predict(S[:,:-1])\n",
    "        self.acc.append(accuracy_score(prd, S[:,-1]))\n",
    "\n",
    "    def sampling_algo(self):\n",
    "        for s in range(self.sample_num):\n",
    "            if self.algo == 'DT':\n",
    "                clf = DecisionTreeClassifier(class_weight=self.class_weight, max_depth=self.max_depth, min_samples_leaf = self.min_samples_leaf)\n",
    "                S = self.sampling()\n",
    "                self.model_gen(clf, S)\n",
    "            else:\n",
    "                clf = SVC(class_weight=self.class_weight, probability=True, C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
    "                S = self.sampling()\n",
    "                self.model_gen(clf, S)\n",
    "        print(\"Accuracy mean of trainning data is : %.6f\" %(np.mean(self.acc)))\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        self.p_num = len(X)\n",
    "        self.p =  np.append(X, Y.reshape(-1,1), axis=1)  # Population, append by row, left + right\n",
    "        self.p0 = self.p[self.p[:,-1] == 0]\n",
    "        self.p1 = self.p[self.p[:,-1] == 1]\n",
    "        self.sampling_algo()\n",
    "            \n",
    "    def major_num(self, batch_pred):\n",
    "        pred = []\n",
    "        for d in batch_pred:\n",
    "            pred.append(0) if np.sum(d==0) >= np.sum(d==1) else pred.append(1)\n",
    "        return np.array(pred)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        batch_pred = []\n",
    "        batch_prob = []\n",
    "        for m in self.algo_model:\n",
    "            batch_pred.append(m.predict(X))\n",
    "            batch_prob.append(m.predict_proba(X)[:,1])\n",
    "        batch_pred = np.array(batch_pred).T\n",
    "        batch_prob = np.array(batch_prob).T\n",
    "        pred = self.major_num(batch_pred)\n",
    "        print(batch_prob)\n",
    "        print(batch_prob.shape)\n",
    "        prob = np.sum(batch_prob, axis =  1)/self.sample_num\n",
    "        print(prob)\n",
    "        return prob, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bagging + DT + balance data\n",
    "根据下面数据发现，在使用balance数据的情况下，不同的分类器是有不同的结果。  \n",
    "我们可以调节抽样次数sample_num和样本大小sample_size来观察结果数据的变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45631, 3) (45631,)\n",
      "(11408, 3)\n",
      "Accuracy mean of trainning data is : 0.729312\n",
      "[[0.07042254 0.1875     0.14358974 ... 0.43225806 0.09473684 0.        ]\n",
      " [0.51851852 0.43478261 0.61111111 ... 0.72294372 0.48571429 0.27941176]\n",
      " [0.39759036 0.61090909 0.44565217 ... 0.43225806 0.4375     0.37068966]\n",
      " ...\n",
      " [0.16666667 0.06470588 0.14358974 ... 0.0952381  0.48571429 0.27941176]\n",
      " [0.07042254 0.1875     0.14358974 ... 0.43225806 0.09473684 0.08988764]\n",
      " [0.07042254 0.06470588 0.02777778 ... 0.0106383  0.09473684 0.06451613]]\n",
      "(11408, 1000)\n",
      "[0.12483438 0.46904604 0.46763098 ... 0.20279603 0.1550008  0.04498955]\n",
      "1000\n",
      "The validation set accuracy is :0.686536\n",
      "The AUC is 0.79749\n",
      "(11408,)\n",
      "[0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "bag = Bagging(algo='DT', sample_num=1000, sample_size=1000, max_depth=3, min_samples_leaf=10,balance=1)\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(verify_x.shape)\n",
    "bag.fit(train_x, train_y)\n",
    "prob_y, pred_y = bag.predict(verify_x)\n",
    "print(len(bag.algo_model))\n",
    "#pred_y = np.array(pred_y)\n",
    "#print(b_pred_y)\n",
    "#print(b_pred_y.shape)\n",
    "#print(b_pred_y[0:20,0:20])\n",
    "#print(pred_y.shape)\n",
    "#print(pred_y[0:50])\n",
    "print(\"The validation set accuracy is :%.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print('The AUC is %.5f' %(roc_auc_score(verify_y, prob_y)))\n",
    "print(prob_y.shape)\n",
    "print(pred_y[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bagging + DT + unbalance data\n",
    "而选择不balance数据的情况下，由于数据偏差比较严重，准确率的均值在78%。分类器发现粗暴的将几乎所有（通过多次实验发现不是所有，极其少量的数据会有1个投票给1）的分类投给数量多的便签类得到的结果会最好。而这样模型也就失去了泛化能力。  \n",
    "但是auc的指标几乎没有变化，这也体现了auc对数据倾斜不过敏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45631, 3) (45631,)\n",
      "Accuracy mean of trainning data is : 0.777966\n",
      "[[0.0877193  0.03065134 0.         ... 0.07446809 0.01895735 0.00621118]\n",
      " [0.26666667 0.27419355 0.18181818 ... 0.27272727 0.1875     0.15625   ]\n",
      " [0.2578125  0.06666667 0.1572327  ... 0.215      0.21794872 0.21264368]\n",
      " ...\n",
      " [0.02164502 0.06818182 0.07086614 ... 0.01515152 0.08759124 0.04458599]\n",
      " [0.0877193  0.03065134 0.         ... 0.07446809 0.01895735 0.00621118]\n",
      " [0.02164502 0.03065134 0.         ... 0.01515152 0.01895735 0.00621118]]\n",
      "(11408, 1000)\n",
      "[0.03860659 0.20486737 0.20463209 ... 0.06571579 0.0484632  0.01508678]\n",
      "1000\n",
      "The validation data accuracy is :0.776736\n",
      "The AUC is 0.79741\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "bag = Bagging(algo='DT', sample_num=1000, sample_size=1000, max_depth=3, min_samples_leaf=10,balance=0)\n",
    "print(train_x.shape, train_y.shape)\n",
    "bag.fit(train_x, train_y)\n",
    "prob_y, pred_y = bag.predict(verify_x)\n",
    "print(len(bag.algo_model))\n",
    "print(\"The validation data accuracy is :%.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print('The AUC is %.5f' %(roc_auc_score(verify_y, prob_y)))\n",
    "print(pred_y[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bagging + svm + balance data\n",
    "由于svm运算时间比较长，所以采样的次数和采样的大小都相对控制的比较小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45631, 3) (45631,)\n",
      "Accuracy mean of trainning data is : 0.800640\n",
      "[[0.31144696 0.30822152 0.33719356 ... 0.18057857 0.24780517 0.25142775]\n",
      " [0.46500364 0.62662928 0.45081123 ... 0.32184763 0.4197097  0.19753491]\n",
      " [0.42967928 0.30756566 0.22708025 ... 0.20864039 0.28507324 0.739645  ]\n",
      " ...\n",
      " [0.5        0.17344801 0.22289104 ... 0.24824761 0.29722095 0.35507473]\n",
      " [0.28068014 0.27091348 0.2154418  ... 0.16989891 0.34907726 0.34077927]\n",
      " [0.34879029 0.28525567 0.32919831 ... 0.31621707 0.31779101 0.30071139]]\n",
      "(11408, 100)\n",
      "[0.28244934 0.48800376 0.39454834 ... 0.25786014 0.28376654 0.30563281]\n",
      "100\n",
      "The validation data accuracy is :0.707223\n",
      "The AUC is 0.784454\n",
      "[0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "bag = Bagging(algo='svc', sample_num=100, sample_size=1000, C=0.8, kernel='rbf', balance=1)\n",
    "print(train_x.shape, train_y.shape)\n",
    "bag.fit(train_x, train_y)\n",
    "prob_y, pred_y = bag.predict(verify_x)\n",
    "print(len(bag.algo_model))\n",
    "print(\"The validation data accuracy is :%.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print(\"The AUC is %.6f\" %(roc_auc_score(verify_y, prob_y)))\n",
    "print(pred_y[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagging + DT + feature modify\n",
    "使用特征改造过的数据（商品和用户id的次数），使用数据平衡，AUC提升9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     12143\n",
      "2      9186\n",
      "3      6198\n",
      "4      4384\n",
      "5      3385\n",
      "      ...  \n",
      "48       48\n",
      "45       45\n",
      "38       38\n",
      "36       36\n",
      "35       35\n",
      "Name: asin, Length: 65, dtype: int64\n",
      "       reviewerID   asin  overall\n",
      "0             759   3385      5.0\n",
      "1            5484   4384      3.0\n",
      "2             928  12143      4.0\n",
      "3            5484   4384      1.0\n",
      "4            5484   1744      5.0\n",
      "...           ...    ...      ...\n",
      "57034        1695    483      2.0\n",
      "57035         945  12143      5.0\n",
      "57036        3040   6198      3.0\n",
      "57037        3816  12143      5.0\n",
      "57038        3060  12143      2.0\n",
      "\n",
      "[57039 rows x 3 columns]\n",
      "(57039, 3)\n",
      "(57039,)\n",
      "(45631, 3) (45631,)\n",
      "Accuracy mean of trainning data is : 0.675112\n",
      "[[0.06202869 0.11586902 0.0470819  ... 0.21531632 0.         0.05616046]\n",
      " [0.52944283 0.11586902 0.18955043 ... 0.55747126 0.35755258 0.40388578]\n",
      " [0.22263642 0.60554003 0.5129771  ... 0.48305599 0.4148066  0.42994242]\n",
      " ...\n",
      " [0.2432662  0.04887675 0.18955043 ... 0.01781451 0.17492984 0.11785929]\n",
      " [0.06202869 0.35721078 0.0470819  ... 0.21531632 0.35755258 0.05616046]\n",
      " [0.06202869 0.04887675 0.0470819  ... 0.01781451 0.03158784 0.        ]]\n",
      "(11408, 1000)\n",
      "[0.11086748 0.44705518 0.4532552  ... 0.19272352 0.15171184 0.03329696]\n",
      "1000\n",
      "The validation data accuracy is :0.686536\n",
      "The AUC is 0.797267\n",
      "[0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.asin.value_counts())\n",
    "asin = dict(train_df['asin'].value_counts())\n",
    "asin_count = train_df['asin'].apply(lambda x: asin[x])\n",
    "reviewid = dict(train_df['reviewerID'].value_counts())\n",
    "reviewid_count = train_df['reviewerID'].apply(lambda x: reviewid[x])\n",
    "train_df['asin'] = asin_count\n",
    "train_df['reviewerID'] = reviewid_count\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText'])\n",
    "print(train_x)\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "trai_x, veri_x, trai_y, veri_y = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
    "\n",
    "bag = Bagging(algo='DT', class_weight='balanced', sample_num=1000, sample_size=1000, max_depth=3, min_samples_leaf=10,balance=0)\n",
    "print(trai_x.shape, trai_y.shape)\n",
    "bag.fit(trai_x, trai_y)\n",
    "prob_y, pred_y = bag.predict(veri_x)\n",
    "print(len(bag.algo_model))\n",
    "#pred_y = np.array(pred_y)\n",
    "#print(b_pred_y)\n",
    "#print(b_pred_y.shape)\n",
    "#print(b_pred_y[0:20,0:20])\n",
    "#print(pred_y.shape)\n",
    "#print(pred_y[0:50])\n",
    "print(\"The validation data accuracy is :%.6f\" %(accuracy_score(pred_y, veri_y)))\n",
    "print(\"The AUC is %.6f\" %(roc_auc_score(veri_y, prob_y)))\n",
    "print(pred_y[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagging + svm + feature modify\n",
    "可能svm是强分类器，并且比较稳定，运用到bigging中效果不好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039, 3) (57039,)\n",
      "Accuracy mean of trainning data is : 0.848400\n",
      "[[0.4213499  0.42498012 0.43384138 ... 0.41863479 0.42884702 0.4178336 ]\n",
      " [0.4213499  0.42498012 0.43384138 ... 0.41863479 0.42884702 0.4178336 ]\n",
      " [0.4213499  0.42498012 0.43384138 ... 0.41863479 0.42884702 0.4178336 ]\n",
      " ...\n",
      " [0.4213499  0.42498012 0.43384138 ... 0.41863479 0.42884702 0.4178336 ]\n",
      " [0.4213499  0.42498012 0.43384138 ... 0.41863479 0.42884702 0.4178336 ]\n",
      " [0.4213499  0.42498012 0.43384138 ... 0.41863479 0.42884702 0.4178336 ]]\n",
      "(11408, 10)\n",
      "[0.4234656 0.4234656 0.4234656 ... 0.4234656 0.4234656 0.4234656]\n",
      "10\n",
      "The validation data accuracy is :0.776736\n",
      "The AUC is 0.500000\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "bag = Bagging(algo='svc', sample_num=10, sample_size=1000, C=0.8, kernel='rbf', balance=1)\n",
    "print(train_x.shape, train_y.shape)\n",
    "bag.fit(train_x, train_y)\n",
    "prob_y, pred_y = bag.predict(verify_x)\n",
    "print(len(bag.algo_model))\n",
    "#pred_y = np.array(pred_y)\n",
    "#print(b_pred_y)\n",
    "#print(b_pred_y.shape)\n",
    "#print(b_pred_y[0:20,0:20])\n",
    "#print(pred_y.shape)\n",
    "#print(pred_y[0:50])\n",
    "print(\"The validation data accuracy is :%.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print(\"The AUC is %.6f\" %(roc_auc_score(verify_y, prob_y)))\n",
    "print(pred_y[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost.m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((45631, 3), (11408, 3), (45631,), (11408,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_y.shape)\n",
    "test_df = pd.read_csv('./data/test.csv', sep='\\t')\n",
    "#train_x\n",
    "test_x = test_df.drop(columns=['Id','reviewText'])\n",
    "\n",
    "train_x, verify_x, train_y, verify_y = train_test_split(train_x, train_y, test_size = 0.2, random_state = 0)\n",
    "train_x.shape, verify_x.shape, train_y.shape, verify_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost(object):\n",
    "    def __init__(self, iters, algo='DT', class_weight=None, max_depth=None, min_samples_leaf=None, C=None, gamma='auto', kernel='rbf'):\n",
    "        self.iters = iters\n",
    "        self.algo = algo\n",
    "        self.class_weight = class_weight\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.algo_model = {}\n",
    "        self.sample_weight = []\n",
    "        self.W = []\n",
    "        self.contrast = []  # predict right or error index\n",
    "        self.result = []\n",
    "        self.rw = []  # result weight, log(1/beta)\n",
    "       \n",
    "    def model_gen(self, P):\n",
    "        if self.algo == 'DT':\n",
    "            clf = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_leaf = self.min_samples_leaf)\n",
    "        else:\n",
    "            clf = SVC(probability=True, C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
    "        clf.fit(P[:,:-1], P[:,-1], sample_weight=self.W)\n",
    "        pred_y = clf.predict(P[:,:-1])\n",
    "        self.contrast = np.array([pred_y == P[:,-1]]).T  # predict right or error index\n",
    "        F_i = np.argwhere(self.contrast == False)[:,0] # true index\n",
    "        epsilon = self.W[F_i].sum()  # error rate\n",
    "        beta = epsilon/(1-epsilon)\n",
    "        self.algo_model[beta] = clf.fit(P[:,:-1], P[:,-1], sample_weight=self.W)\n",
    "        return epsilon, beta\n",
    "        \n",
    "    def weight_update(self, epsilon, beta):\n",
    "        T_i = np.argwhere(self.contrast == True)[:,0]   # true index\n",
    "        self.W[T_i] = self.W[T_i] * beta\n",
    "        self.W = self.W/self.W.sum()\n",
    "                \n",
    "    def classifier_gen(self, P):\n",
    "        for m in range(self.iters):\n",
    "            epsilon, beta = self.model_gen(P)\n",
    "            if epsilon > 0.5: \n",
    "                continue\n",
    "            self.weight_update(epsilon, beta)\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.W = np.linspace(1/len(X), 1/len(X), len(X))\n",
    "        P = np.append(X, Y.reshape(-1,1), axis = 1)\n",
    "        print(P.shape)\n",
    "        self.classifier_gen(P)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        for k, v in self.algo_model.items():\n",
    "            self.result.append(v.predict_proba(X))\n",
    "            a = v.predict_proba(X)\n",
    "            self.rw.append(np.log2(1/k))\n",
    "        self.result = np.array(self.result)\n",
    "        self.rw = np.array(self.rw)\n",
    "        zero = self.result[:,:,0]\n",
    "        one = self.result[:,:,1]\n",
    "        zerow = zero * self.rw.reshape(-1,1)\n",
    "        onew = one * self.rw.reshape(-1,1)\n",
    "        zerow = np.sum(zerow, axis = 0)/self.iters\n",
    "        onew = np.sum(onew, axis = 0)/self.iters\n",
    "        no = zerow+onew\n",
    "        zerow = zerow/no\n",
    "        onew = onew/no\n",
    "        tmp = []\n",
    "        for i in onew:\n",
    "            tmp.append(1) if i >= 0.475 else tmp.append(0)\n",
    "        return np.array(tmp), onew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost.m1 + Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45631, 3) (45631,)\n",
      "(45631, 4)\n",
      "[0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1]\n",
      "Accuracy is 0.734309\n",
      "[0.37632321 0.40385517 0.47192363 ... 0.38023906 0.38731852 0.34582602]\n",
      "auc is 0.793306 \n"
     ]
    }
   ],
   "source": [
    "ada = Adaboost(algo='DT', iters=1000, class_weight='balanced', max_depth=1, min_samples_leaf=10)\n",
    "#ada = Adaboost(algo='DT', iters=10, max_depth=3, min_samples_leaf=10)\n",
    "print(train_x.shape, train_y.shape)\n",
    "ada.fit(train_x, train_y)\n",
    "pred_y, prob_y = ada.predict(verify_x)\n",
    "print(pred_y[0:30])\n",
    "print(\"Accuracy is %.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print(prob_y)\n",
    "print(\"auc is %.6f \" %(roc_auc_score(verify_y, prob_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost.m1 + DT + feature modify\n",
    "再bagging中，对特征改造后评价指标有明显的上升，在adaboost中也尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12143    12143\n",
      "9186      9186\n",
      "6198      6198\n",
      "4384      4384\n",
      "3385      3385\n",
      "         ...  \n",
      "48          48\n",
      "45          45\n",
      "38          38\n",
      "36          36\n",
      "35          35\n",
      "Name: asin, Length: 64, dtype: int64\n",
      "       reviewerID   asin  overall\n",
      "0             759   3385      5.0\n",
      "1            5484   4384      3.0\n",
      "2             928  12143      4.0\n",
      "3            5484   4384      1.0\n",
      "4            5484   1744      5.0\n",
      "...           ...    ...      ...\n",
      "57034        1695    483      2.0\n",
      "57035         945  12143      5.0\n",
      "57036        3040   6198      3.0\n",
      "57037        3816  12143      5.0\n",
      "57038        3060  12143      2.0\n",
      "\n",
      "[57039 rows x 3 columns]\n",
      "(57039, 3)\n",
      "(57039,)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.asin.value_counts())\n",
    "asin = dict(train_df['asin'].value_counts())\n",
    "asin_count = train_df['asin'].apply(lambda x: asin[x])\n",
    "reviewid = dict(train_df['reviewerID'].value_counts())\n",
    "reviewid_count = train_df['reviewerID'].apply(lambda x: reviewid[x])\n",
    "train_df['asin'] = asin_count\n",
    "train_df['reviewerID'] = reviewid_count\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText'])\n",
    "print(train_x)\n",
    "train_x = train_df.iloc[:, :-3].drop(columns=['reviewText']).values\n",
    "train_y = train_df.label.values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "trai_x, veri_x, trai_y, veri_y = train_test_split(train_x, train_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039, 3) (57039,)\n",
      "(57039, 4)\n",
      "[0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1]\n",
      "Accuracy is 0.734309\n",
      "[0.374124   0.40238259 0.47202788 ... 0.37807378 0.38518329 0.34242225]\n",
      "auc is 0.793571 \n"
     ]
    }
   ],
   "source": [
    "ada = Adaboost(algo='DT', iters=1000, class_weight='balanced', max_depth=1, min_samples_leaf=10)\n",
    "print(train_x.shape, train_y.shape)\n",
    "ada.fit(train_x, train_y)\n",
    "pred_y, prob_y = ada.predict(verify_x)\n",
    "print(pred_y[0:30])\n",
    "print(\"Accuracy is %.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print(prob_y)\n",
    "print(\"auc is %.6f \" %(roc_auc_score(verify_y, prob_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调库来看看和自己的实现的差距~  \n",
    "bagging + DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1]\n",
      "accuracy is 0.595810\n",
      "auc is 0.701907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "tree = DecisionTreeClassifier(class_weight='balanced', max_depth=1, min_samples_leaf = 10)\n",
    "clf = BaggingClassifier(base_estimator=tree, n_estimators=1000, max_samples=1.0, bootstrap=True, bootstrap_features=False, random_state=0)\n",
    "clf.fit(train_x, train_y)\n",
    "pred_y = clf.predict(verify_x)\n",
    "prob_y = clf.predict_proba(verify_x)\n",
    "print(pred_y[0:30])\n",
    "print(\"accuracy is %.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "print('auc is %.6f' %(roc_auc_score(verify_y, prob_y[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1]\n",
      "accuracy is 0.689078\n",
      "0.8006870673345394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "tree = DecisionTreeClassifier(class_weight='balanced', max_depth = 1, min_samples_leaf = 10)\n",
    "clf = AdaBoostClassifier(base_estimator=tree, n_estimators=1000, learning_rate=0.9)\n",
    "clf.fit(train_x, train_y)\n",
    "pred_y = clf.predict(verify_x)\n",
    "prob_y = clf.predict_proba(verify_x)\n",
    "print(pred_y[0:30])\n",
    "print(\"accuracy is %.6f\" %(accuracy_score(pred_y, verify_y)))\n",
    "auc = roc_auc_score(verify_y, prob_y[:,1])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
